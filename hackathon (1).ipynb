{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This hackathon was done by Haifa Al Ashkar ID:202201534"
      ],
      "metadata": {
        "id": "5Z4WOPSPUICH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*note: upload the dataset and rename it to Survey*"
      ],
      "metadata": {
        "id": "idJY3UvJUTbd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Objective\n",
        "The objective of this project is to predict the number of cigarettes smoked daily based on socio-economic, psychological, and behavioral factors. This can help in understanding smoking patterns and targeting interventions for smokers."
      ],
      "metadata": {
        "id": "vcXcQPhXPrPW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Why Choose These Features?\n",
        "### Behavioral Traits:\n",
        "Features like \"difficulty refraining from smoking in forbidden places\" and \"time to first cigarette after waking up\" are strong indicators of nicotine dependency.\n",
        "### Socio-Economic Factors:\n",
        "Income levels and peer influence are known to significantly affect smoking habits.\n",
        "### Personality Traits:\n",
        "Psychological traits such as anxiety and creativity might be linked to smoking behavior.\n",
        "These features provide a mix of behavioral, economic, and psychological variables for comprehensive prediction.\n",
        "\n"
      ],
      "metadata": {
        "id": "Dwe00xaiSalv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Steps Taken to Clean Data\n",
        "\n",
        "1. **Replace Non-Informative Entries**:\n",
        "   - Replaced responses like `\"I don't know\"`, `\"I prefer not to say\"`, and `\"Prefer not to answer\"` with `NaN`.\n",
        "\n",
        "2. **Handle Categorical Columns with Ordinal Encoding**:\n",
        "   - Encoded Likert-scale responses for personality traits, mapping `\"Disagree strongly\"` to `1` and `\"Agree strongly\"` to `7`.\n",
        "   - Mapped other ordinal columns such as:\n",
        "     - **Smoking behavior**: `\"10 or less cigarettes/day\"` → `1`, `\"31 cigarettes/day or more\"` → `4`.\n",
        "     - **Stress levels**: `\"Never\"` → `1`, `\"Constantly\"` → `5`.\n",
        "     - **Exercise frequency**, **income ranges**, and similar ordinal responses were encoded with numerical scales.\n",
        "\n",
        "3. **Binary Encoding**:\n",
        "   - Converted `Yes/No` responses to `1/0`.\n",
        "   - Encoded gender as `\"Male\"` → `1` and `\"Female\"` → `0`.\n",
        "   - Encoded sector type as `\"Public\"` → `1` and `\"Private\"` → `0`.\n",
        "\n",
        "4. **Standardize Cigarette Brands**:\n",
        "   - Standardized brand names like `\"Marlboro Gold\"`, `\"Malboro\"`, and `\"Malborow\"` into `\"Marlboro\"`.\n",
        "   - Grouped rare brands under `\"Others\"`.\n",
        "\n",
        "5. **One-Hot Encoding**:\n",
        "   - Applied one-hot encoding to categorical variables such as:\n",
        "     - **Employment status**.\n",
        "     - **Favorite cigarette brands**.\n",
        "     - **Governorates** (regions).\n",
        "     - **Income sources**.\n",
        "\n",
        "6. **Handle Missing Values**:\n",
        "   - Filled missing values with `0` or appropriate strategies (e.g., `mean`/`median`) based on column type.\n",
        "\n",
        "7. **Remove Irrelevant Columns**:\n",
        "   - Dropped columns containing `\"comments\"` in their names to avoid free-text data.\n",
        "\n",
        "8. **Map Frequency-Based Columns**:\n",
        "   - Mapped ordinal frequency-based responses like:\n",
        "     - **\"How often do you feel stressed?\"**: `\"Never\"` → `1`, `\"Constantly\"` → `5`.\n",
        "     - **\"On average, how many hours per day do you spend on social media?\"**: `\"Less than 1 hour\"` → `1`, `\"More than 4 hours\"` → `4`.\n",
        "\n",
        "9. **Final Dataset**:\n",
        "   - The dataset is now clean, numerical, and ready for use in machine learning models.\n"
      ],
      "metadata": {
        "id": "ZGuzC2AjTLY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6p-Frr7efA9k",
        "outputId": "1e0788c9-ad45-4748-d5a7-fb2000b081f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data cleaning completed. Cleaned data saved as 'cleaned_survey_data.csv'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-9c47d61970e0>:42: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
            "  data = data.replace({\"Yes\": 1, \"No\": 0})\n",
            "<ipython-input-22-9c47d61970e0>:205: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[\"If you receive payment in Lebanese Lira, what is your current estimated monthly household income? (If income is in US Dollars, then refer to the current black market exchange).\"].fillna(0, inplace=True)\n",
            "<ipython-input-22-9c47d61970e0>:220: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[\"How would you describe your current income sufficiency?\"].fillna(0, inplace=True)  # Replace with 0 or use a strategy like mean/median\n",
            "<ipython-input-22-9c47d61970e0>:235: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[\"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\"].fillna(0, inplace=True)  # Replace with 0 or another strategy like mean/median\n",
            "<ipython-input-22-9c47d61970e0>:251: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[\"On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)?\"].fillna(0, inplace=True)  # Replace with 0 or another strategy like mean/median\n",
            "<ipython-input-22-9c47d61970e0>:263: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  data[\"Employment Status\"].fillna(0, inplace=True)  # Replace with 0 (assumes missing = \"Unemployed\") or another strategy\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
        "import numpy as np\n",
        "\n",
        "def clean_survey_data(data):\n",
        "    # Replace non-informative entries with NaN\n",
        "    non_informative = [\"I don't know\", \"I prefer not to say\", \"Prefer not to answer\"]\n",
        "    data.replace(non_informative, np.nan, inplace=True)\n",
        "\n",
        "\n",
        "    # Ordinal encoding for Likert-scale personality traits\n",
        "    likert_scale_mapping = {\n",
        "        \"Disagree strongly\": 1,\n",
        "        \"Disagree moderately\": 2,\n",
        "        \"Disagree a little\": 3,\n",
        "        \"Neither agree nor disagree\": 4,\n",
        "        \"Agree a little\": 5,\n",
        "        \"Agree moderately\": 6,\n",
        "        \"Agree strongly\": 7\n",
        "    }\n",
        "    likert_scale_columns = [\n",
        "        \"I see myself as someone who is extraverted, enthusiastic:\",\n",
        "        \"I see myself as someone who is critical, quarrelsome:\",\n",
        "        \"I see myself as someone who is dependable, self-disciplined:\",\n",
        "        \"I see myself as someone who is anxious, easily upset:\",\n",
        "        \"I see myself as someone who is open to new experiences:\",\n",
        "        \"I see myself as someone who is reserved, quiet:\",\n",
        "        \"I see myself as someone who is sympathetic, warm:\",\n",
        "        \"I see myself as someone who is disorganized, careless:\",\n",
        "        \"I see myself as someone who is calm, emotionally stable:\",\n",
        "        \"I see myself as someone who is conventional, uncreative:\"\n",
        "    ]\n",
        "    for col in likert_scale_columns:\n",
        "        if col in data.columns:\n",
        "            data[col] = data[col].map(likert_scale_mapping)\n",
        "\n",
        "    gender_mapping = {\"Male\": 1, \"Female\": 0}\n",
        "    data[\"Gender:\"] = data[\"Gender:\"].map(gender_mapping)\n",
        "\n",
        "    # data.columns = data.columns.str.strip().str.replace(r'[^\\w\\s\\(\\)\\?\\,\\.0-9\\']', '', regex=True)\n",
        "# Replace all \"Yes\" with 1 and \"No\" with 0 across the entire dataset\n",
        "    data = data.replace({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "\n",
        "        # Encode Yes/No and True/False values\n",
        "    # yes_no_cols = [\n",
        "    #     \"Have you smoked at least one full tobacco cigarette (excluding e-cigarettes) once or more in the past 30 days?\",\n",
        "    #     \"Do you find it difficult to refrain from smoking where it is forbidden (church, library, cinema, plane, etc...)?\",\n",
        "    #     \"Do you smoke more frequently during the first hours after waking up than during the rest of the day?Â\",\n",
        "    #     \"Do you smoke if you are so ill that you are in bed most of the day?\",\n",
        "    #     \"Are you currently able to afford your favorite or preferred cigarette brand(s)?\",\n",
        "    #     \"Do you have close friends?\",\n",
        "\n",
        "    # ]\n",
        "    # for col in yes_no_cols:\n",
        "    #     if col in data.columns:\n",
        "    #         data[col] = data[col].map({\"Yes\": 1, \"No\": 0})\n",
        "\n",
        "    sector_col =[\"Sector\"]\n",
        "    for col in sector_col:\n",
        "        if col in data.columns:\n",
        "            data[col] = data[col].map({\"Public\": 1, \"Private\": 0})\n",
        "\n",
        "    # Ordinal encode frequency-based columns\n",
        "    stress_mapping = {\"Never\": 1, \"Rarely\": 2, \"Occasionally\": 3, \"Frequently\": 4, \"Constantly\": 5}\n",
        "    exercise_mapping = {\"Never\": 1, \"Rarely\": 2, \"Often or at least 3 days every week\": 3, \"Every day or at least 5 times every week\": 4}\n",
        "    social_media_mapping = {\n",
        "        \"Less than 1 hour\": 1,\n",
        "        \"Between 1 and 2 hours\": 2,\n",
        "        \"Between 2 and 3 hours\": 3,\n",
        "        \"More than 4 hours\": 4\n",
        "    }\n",
        "\n",
        "    if \"How often do you feel stressed?\" in data.columns:\n",
        "        data[\"How often do you feel stressed?\"] = data[\"How often do you feel stressed?\"].map(stress_mapping)\n",
        "    if \"How often do you exercise?\" in data.columns:\n",
        "        data[\"How often do you exercise?\"] = data[\"How often do you exercise?\"].map(exercise_mapping)\n",
        "    if \"On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)\" in data.columns:\n",
        "        data[\"On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)\"] = data[\"On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)\"].map(social_media_mapping)\n",
        "\n",
        "    # One-hot encode employment status\n",
        "    employment_column = \"What is your current employment status?\"\n",
        "    if employment_column in data.columns:\n",
        "        data = pd.get_dummies(data, columns=[employment_column], drop_first=True)\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    cigarettes_mapping = {\n",
        "        \"10 or less cigarettes/day\": 1,\n",
        "        \"11 to 20 cigarettes\": 2,\n",
        "        \"21 to 30 cigarettes\": 3,\n",
        "        \"31 cigarettes/day or more\": 4\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"How many cigarettes do you smoke each day?\"] = data[\"How many cigarettes do you smoke each day?\"].map(cigarettes_mapping)\n",
        "\n",
        "  # Define the mapping for ordinal encoding\n",
        "    wake_up_cigarette_mapping = {\n",
        "        \"Within 5 minutes\": 1,\n",
        "        \"6 to 30 minutes\": 2,\n",
        "        \"31 to 60 minutes\": 3,\n",
        "        \"After 60 minutes\": 4\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"How soon after you wake up do you smoke your first cigarette?\"] = data[\"How soon after you wake up do you smoke your first cigarette?\"].map(wake_up_cigarette_mapping)\n",
        "\n",
        "    # Define the mapping for binary encoding\n",
        "    cigarette_preference_mapping = {\n",
        "        \"The first one in the morning\": 1,\n",
        "        \"All others\": 0\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"Which cigarette would you mostly hate to give up?\"] = data[\"Which cigarette would you mostly hate to give up?\"].map(cigarette_preference_mapping)\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    smoking_behavior_mapping = {\n",
        "        \"The number of cigarettes I smoke per day has decreased\": 1,\n",
        "        \"The number of cigarettes I smoke per day has remained the same\": 2,\n",
        "        \"The number of cigarettes I smoke per day has increased\": 3\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"How would you describe your current smoking behavior compared to your smoking behavior before Lebanon's economic crisis and revolution began in 2019?\"] = data[\"How would you describe your current smoking behavior compared to your smoking behavior before Lebanon's economic crisis and revolution began in 2019?\"].map(smoking_behavior_mapping)\n",
        "\n",
        "    # Define the mapping for cigarette brands\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"What is your favorite or preferred cigarette brand(s) if you were able to access it?\"] = data[\"What is your favorite or preferred cigarette brand(s) if you were able to access it?\"].apply(map_brand)\n",
        "\n",
        "    # One-hot encode the standardized brands\n",
        "    data = pd.get_dummies(data, columns=[\"What is your favorite or preferred cigarette brand(s) if you were able to access it?\"], prefix=\"Brand\")\n",
        "\n",
        "    data[\"What cigarette brand(s) are you currently using?\"] = data[\"What cigarette brand(s) are you currently using?\"].apply(map_brand)\n",
        "\n",
        "    # One-hot encode the standardized brands\n",
        "    data = pd.get_dummies(data, columns=[\"What cigarette brand(s) are you currently using?\"], prefix=\"Current_Brand\")\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    switch_mapping = {\n",
        "        \"No, I am currently using my favorite or preferred cigarette brand(s)\": 0,\n",
        "        \"Yes, I am currently using a cheaper alternative\": 1,\n",
        "        \"Yes, I am currently using a more expensive alternative\": 2\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"Has 2019's revolution or economic crisis caused you to switch away from your favorite or preferred cigarette brand(s) to an  alternative?\"] = data[\"Has 2019's revolution or economic crisis caused you to switch away from your favorite or preferred cigarette brand(s) to an  alternative?\"].map(switch_mapping)\n",
        "\n",
        "    # One-hot encode the governorates column\n",
        "    data = pd.get_dummies(data, columns=[\"Which governerate do you live in or spend most of your time in?\"], prefix=\"Governorate\")\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    education_mapping = {\n",
        "        \"Less than high school\": 1,\n",
        "        \"High school degree or equivalent (e.g. GED)\": 2,\n",
        "        \"Incomplete bachelor's degree\": 3,\n",
        "        \"Bachelor's degree (BA/BS)\": 4,\n",
        "        \"Incomplete graduate degree\": 5,\n",
        "        \"Graduate degree (MA/MS)\": 6,\n",
        "        \"Post-graduate degree (PhD, MD, or other)\": 7\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"What is the highest level of education you have attained?\"] = data[\"What is the highest level of education you have attained?\"].map(education_mapping)\n",
        "\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    marital_status_mapping = {\n",
        "        \"Single\": 1,\n",
        "        \"Engaged\": 2,\n",
        "        \"Married\": 3,\n",
        "        \"Divorced/Separated\": 4,\n",
        "        \"Other, please specify\": 5  # Treating \"Other\" as a separate category\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"What is your current marital status?\"] = data[\"What is your current marital status?\"].map(marital_status_mapping)\n",
        "\n",
        "\n",
        "    # One-hot encode the main source of income\n",
        "    data = pd.get_dummies(data, columns=[\"What is your main source of income?\"], prefix=\"Income_Source\")\n",
        "\n",
        "    # One-hot encode the income/financial support column\n",
        "    data = pd.get_dummies(data, columns=[\"What type of income or financial support does your household receive?\"], prefix=\"Income_Type\")\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    income_mapping = {\n",
        "        \"Less than 1 million L.L\": 1,\n",
        "        \"Between 1 and 4 million L.L\": 2,\n",
        "        \"Between 4 and 8 million L.L\": 3,\n",
        "        \"Between 8 and 12 million L.L\": 4,\n",
        "        \"Between 12 and 16 million L.L\": 5,\n",
        "        \"Between 16 and 20 million L.L\": 6,\n",
        "        \"More than 20 million L.L\": 7\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"If you receive payment in Lebanese Lira, what is your current estimated monthly household income? (If income is in US Dollars, then refer to the current black market exchange).\"] = data[\"If you receive payment in Lebanese Lira, what is your current estimated monthly household income? (If income is in US Dollars, then refer to the current black market exchange).\"].map(income_mapping)\n",
        "\n",
        "    # Handle missing values by filling with 0 or another strategy (e.g., mean, median)\n",
        "    data[\"If you receive payment in Lebanese Lira, what is your current estimated monthly household income? (If income is in US Dollars, then refer to the current black market exchange).\"].fillna(0, inplace=True)\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    income_sufficiency_mapping = {\n",
        "        \"Very low income: does not cover basic needs for a month\": 1,\n",
        "        \"Low: barely covers basic needs for a month\": 2,\n",
        "        \"Medium: covers all basic needs\": 3,\n",
        "        \"High: completely covers necessities with a few luxury items\": 4,\n",
        "        \"Extremely high: covers a wide range of luxury items\": 5\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"How would you describe your current income sufficiency?\"] = data[\"How would you describe your current income sufficiency?\"].map(income_sufficiency_mapping)\n",
        "\n",
        "    # Handle missing values (if any exist)\n",
        "    data[\"How would you describe your current income sufficiency?\"].fillna(0, inplace=True)  # Replace with 0 or use a strategy like mean/median\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    financial_impact_mapping = {\n",
        "        \"Not at all\": 1,\n",
        "        \"Slightly\": 2,\n",
        "        \"Moderately\": 3,\n",
        "        \"Very\": 4,\n",
        "        \"Extremely\": 5\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\"] = data[\"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\"].map(financial_impact_mapping)\n",
        "\n",
        "    # Handle missing values (if any exist)\n",
        "    data[\"To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?\"].fillna(0, inplace=True)  # Replace with 0 or another strategy like mean/median\n",
        "\n",
        "    # Define the mapping for ordinal encoding\n",
        "    social_media_usage_mapping = {\n",
        "        \"I don't use any social media platforms\": 0,\n",
        "        \"Less than 1 hour\": 1,\n",
        "        \"Between 1 hour and 2 hours\": 2,\n",
        "        \"Between 2 and 3 hours\": 3,\n",
        "        \"Between 3 and 4 hours\": 4,\n",
        "        \"More than 4 hours\": 5\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)?\"] = data[\"On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)?\"].map(social_media_usage_mapping)\n",
        "\n",
        "    # Handle missing values (if any exist)\n",
        "    data[\"On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)?\"].fillna(0, inplace=True)  # Replace with 0 or another strategy like mean/median\n",
        "\n",
        "        # Define the mapping for binary encoding\n",
        "    employment_status_mapping = {\n",
        "        \"Employed\": 1,\n",
        "        \"Unemployed\": 0\n",
        "    }\n",
        "\n",
        "    # Apply the mapping to the column\n",
        "    data[\"Employment Status\"] = data[\"Employment Status\"].map(employment_status_mapping)\n",
        "\n",
        "    # Handle missing values (if any exist)\n",
        "    data[\"Employment Status\"].fillna(0, inplace=True)  # Replace with 0 (assumes missing = \"Unemployed\") or another strategy\n",
        "\n",
        "    # Drop all columns that contain \"comments\" in their names\n",
        "    data = data.loc[:, ~data.columns.str.contains(\"comment\", case=False)]\n",
        "\n",
        "\n",
        "    return data\n",
        "\n",
        "brand_mapping = {\n",
        "        \"Marlboro\": \"Marlboro\",\n",
        "        \"Marlboro Gold\": \"Marlboro\",\n",
        "        \"Malboro\": \"Marlboro\",\n",
        "        \"Malborow\": \"Marlboro\",\n",
        "        \"Marlboro Red\": \"Marlboro\",\n",
        "        \"Davidoff\": \"Davidoff\",\n",
        "        \"Kent\": \"Kent\",\n",
        "        \"Camel\": \"Camel\",\n",
        "        \"Cedars\": \"Cedars\",\n",
        "        \"Heets\": \"Heets\",\n",
        "        \"Winston\": \"Winston\",\n",
        "        \"IQOS\": \"IQOS\",\n",
        "        # Combine similar rare brands into 'Others'\n",
        "        \"Other\": \"Others\",\n",
        "        \"Cohiba\": \"Others\",\n",
        "        \"Golden Virginia\": \"Others\",\n",
        "        \"Parliament\": \"Others\",\n",
        "        \"Gitanes\": \"Others\",\n",
        "        \"Rolling Tobacco\": \"Others\",\n",
        "    }\n",
        "# Function to standardize brand names\n",
        "def map_brand(value):\n",
        "    # Ensure case insensitivity and remove extraneous characters\n",
        "    value = str(value).lower().strip()\n",
        "    for key, standardized in brand_mapping.items():\n",
        "        if key.lower() in value:\n",
        "            return standardized\n",
        "    return \"Others\"  # Default to 'Others' for unknown brands\n",
        "# Load the dataset\n",
        "file_path = 'Survey.xls'  # Update the path to your file\n",
        "data = pd.read_excel(file_path)\n",
        "\n",
        "# Clean the dataset\n",
        "cleaned_data = clean_survey_data(data)\n",
        "\n",
        "# Save or inspect the cleaned data\n",
        "cleaned_data.to_csv('cleaned_survey_data.csv', index=False)\n",
        "print(\"Data cleaning completed. Cleaned data saved as 'cleaned_survey_data.csv'.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load the dataset\n",
        "file_path = 'cleaned_survey_data.csv'  # Replace with the actual path\n",
        "data = pd.read_csv(file_path)\n",
        "\n",
        "# Step 1: Drop Irrelevant or Redundant Columns\n",
        "columns_to_drop = [\n",
        "    'Unnamed: 0',  # Index column\n",
        "    'Last page',  # Metadata\n",
        "    'What is your current marital status? [Comment]',  # Redundant\n",
        "    'What is your main source of income? [Comment]',  # Sparse free-text data\n",
        "    'What type of income or financial support does your household receive? [Comment]',  # Sparse free-text data\n",
        "    'Employment Status'  # Original column, if one-hot encoded columns are present\n",
        "]\n",
        "data = data.drop(columns=columns_to_drop, errors='ignore')\n",
        "\n",
        "# Step 2: Handle Missing Values\n",
        "# Fill missing values for numerical features with the median\n",
        "for col in data.select_dtypes(include=['float64', 'int64']).columns:\n",
        "    data[col] = data[col].fillna(data[col].median())\n",
        "\n",
        "# Step 3: Prepare Target and Features\n",
        "target_column = 'How many cigarettes do you smoke each day?'  # Target variable\n",
        "X = data.drop(columns=[target_column], errors='ignore')  # Features\n",
        "y = data[target_column]  # Target\n",
        "\n",
        "# Step 4: Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Output the preprocessed dataset shapes\n",
        "print(\"X_train shape:\", X_train.shape)\n",
        "print(\"X_test shape:\", X_test.shape)\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_test shape:\", y_test.shape)\n",
        "\n",
        "# Optional: Display the remaining columns in X to verify\n",
        "print(\"Features in the dataset after preprocessing:\")\n",
        "print(X.columns.tolist())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFqxji0Vq9-1",
        "outputId": "8b8b4a59-6b99-4236-8897-7d37b11ec4b2"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (169, 76)\n",
            "X_test shape: (43, 76)\n",
            "y_train shape: (169,)\n",
            "y_test shape: (43,)\n",
            "Features in the dataset after preprocessing:\n",
            "['Sector', 'Have you smoked at least one full tobacco cigarette (excluding e-cigarettes) once or more in the past 30 days?', 'I see myself as someone who is extraverted, enthusiastic:', 'I see myself as someone who is critical, quarrelsome:', 'I see myself as someone who is dependable, self-disciplined:', 'I see myself as someone who is anxious, easily upset:', 'I see myself as someone who is open to new experiences:', 'I see myself as someone who is reserved, quiet:', 'I see myself as someone who is sympathetic, warm:', 'I see myself as someone who is disorganized, careless:', 'I see myself as someone who is calm, emotionally stable:', 'I see myself as someone who is conventional, uncreative:', 'Do you find it difficult to refrain from smoking where it is forbidden (church, library, cinema, plane, etc...)?', 'Do you smoke more frequently during the first hours after waking up than during the rest of the day?\\xa0', 'Do you smoke if you are so ill that you are in bed most of the day?', 'How soon after you wake up do you smoke your first cigarette?', 'Which cigarette would you mostly hate to give up?', 'How old were you the first time you smoked a full cigarette (not just a few puffs)?', \"How would you describe your current smoking behavior compared to your smoking behavior before Lebanon's economic crisis and revolution began in 2019?\", 'Are you currently able to afford your favorite or preferred cigarette brand(s)?', \"Has 2019's revolution or economic crisis caused you to switch away from your favorite or preferred cigarette brand(s) to an\\xa0 alternative?\", 'Gender:', 'How old are you?', 'What is the highest level of education you have attained?', 'What is your current marital status?', 'Do you have close friends?', 'Of the five closest friends or acquaintances that you spend time with on a regular basis, how many of them are smokers?', 'If you receive payment in Lebanese Lira, what is your current estimated monthly household income? (If income is in US Dollars, then refer to the current black market exchange).', 'How would you describe your current income sufficiency?', 'Including yourself, how many people currently live in your household?', 'To what extent were you financially (negatively) affected by the deterioration of the Lebanese economy?', 'How often do you exercise?', 'On average, how many hours per day do you spend on social media for entertainment and social interaction (Facebook, Instagram, YouTube, etc...)?', 'How often do you feel stressed?', 'What is your current employment status?_Employee; full-time', 'What is your current employment status?_Employee; part-time', 'What is your current employment status?_Homemaker', 'What is your current employment status?_Other, please specify', 'What is your current employment status?_Student only', 'What is your current employment status?_Student with a part-time or full-time job', 'What is your current employment status?_Unemployed (but seeking employment)', 'Brand_Camel', 'Brand_Cedars', 'Brand_Davidoff', 'Brand_Heets', 'Brand_IQOS', 'Brand_Kent', 'Brand_Marlboro', 'Brand_Others', 'Brand_Winston', 'Current_Brand_Camel', 'Current_Brand_Cedars', 'Current_Brand_Davidoff', 'Current_Brand_Heets', 'Current_Brand_IQOS', 'Current_Brand_Kent', 'Current_Brand_Marlboro', 'Current_Brand_Others', 'Current_Brand_Winston', 'Governorate_Baalbeck - Hermel', 'Governorate_Beirut', 'Governorate_Beqaa', 'Governorate_Keserwan - Jbeil', 'Governorate_Mount Lebanon', 'Governorate_Nabatieh', 'Governorate_North Lebanon', 'Governorate_South Lebanon', 'Income_Source_Investment', 'Income_Source_Job', 'Income_Source_Other, please specify', 'Income_Source_Own business income', 'Income_Source_Parents', 'Income_Type_Fully in Lebanese Lira', 'Income_Type_Fully in US Dollars', 'Income_Type_Mixed', 'Income_Type_Other, please specify']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Model Used and Why\n",
        "###Random Forest Regressor:\n",
        "\n",
        "####Why?:\n",
        "Handles mixed data types (categorical and numerical).\n",
        "Robust to outliers and missing values.\n",
        "Automatically captures non-linear relationships and feature interactions.\n"
      ],
      "metadata": {
        "id": "--gFMzZoTq0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Train the Random Forest Regressor\n",
        "rf_model = RandomForestRegressor(random_state=42)\n",
        "rf_model.fit(X_train, y_train)\n",
        "\n",
        "# Step 2: Make Predictions\n",
        "y_pred = rf_model.predict(X_test)\n",
        "\n",
        "# Step 3: Evaluate the Model\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
        "\n",
        "# Step 4: Feature Importance\n",
        "feature_importances = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': rf_model.feature_importances_\n",
        "}).sort_values(by='Importance', ascending=False)\n",
        "\n",
        "# Print Performance Metrics\n",
        "print(\"Mean Absolute Error (MAE):\", mae)\n",
        "print(\"Root Mean Squared Error (RMSE):\", rmse)\n",
        "\n",
        "# Display Feature Importance\n",
        "print(\"Top 10 Important Features:\")\n",
        "print(feature_importances.head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Rp4K3Rdq3w_",
        "outputId": "f23f4ef7-1f0b-4848-b8bc-d98054ab5834"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Absolute Error (MAE): 0.4813953488372093\n",
            "Root Mean Squared Error (RMSE): 0.6270788682269114\n",
            "Top 10 Important Features:\n",
            "                                              Feature  Importance\n",
            "12  Do you find it difficult to refrain from smoki...    0.259658\n",
            "27  If you receive payment in Lebanese Lira, what ...    0.202230\n",
            "15  How soon after you wake up do you smoke your f...    0.108875\n",
            "11  I see myself as someone who is conventional, u...    0.042947\n",
            "5   I see myself as someone who is anxious, easily...    0.027044\n",
            "26  Of the five closest friends or acquaintances t...    0.025731\n",
            "13  Do you smoke more frequently during the first ...    0.023241\n",
            "17  How old were you the first time you smoked a f...    0.023197\n",
            "29  Including yourself, how many people currently ...    0.022417\n",
            "22                                   How old are you?    0.017080\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Results Analysis\n",
        "##Performance Metrics:\n",
        "\n",
        "**Mean Absolute Error (MAE)**: 0.48 cigarettes/day.\n",
        "**Root Mean Squared Error (RMSE)**: 0.63 cigarettes/day.\n",
        "The model shows good predictive accuracy for this dataset.\n",
        "Key Features:\n",
        "\n",
        "###Top Predictors:\n",
        "\"Difficulty refraining from smoking in forbidden places\" (25.9% importance).\n",
        "\"Monthly household income in Lebanese Lira\" (20.2% importance).\n",
        "\"Time to first cigarette after waking up\" (10.8% importance).\n",
        "Behavioral features dominate the prediction, with socio-economic and personality traits contributing less but still significant.\n",
        "###Insights:\n",
        "\n",
        "Smoking habits are heavily influenced by addiction-related behaviors and economic stress.\n",
        "Personality traits like anxiety and conformity also play a role, albeit smaller."
      ],
      "metadata": {
        "id": "yNuSyt5vSRU9"
      }
    }
  ]
}